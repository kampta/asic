import torch
import torch.nn as nn
import torch.nn.functional as F

from thirdparty.unet.unet import UNet


class Asic(nn.Module):
    def __init__(self, in_ch, in_size, mf=1., bilinear=False,
                 padding_mode='zeros', use_tanh=False):
        super().__init__()
        self.model = UNet(in_ch, 2, mf=mf, bilinear=bilinear)
        self.size = in_size
        self.register_buffer('identity_flow', self.get_identity_flow())
        self.padding_mode = padding_mode
        self.use_tanh = use_tanh

    def get_identity_flow(self):
        return F.affine_grid(
            torch.eye(2, 3).unsqueeze(0), (1, 1, self.size, self.size),
            align_corners=True).permute(0, 3, 1, 2).contiguous()

    def forward(self, x):
        if self.use_tanh:
            flow = torch.tanh(self.model(x))
            delta_flow = flow - self.identity_flow
        else:
            delta_flow = self.model(x)  # (N, 2, H, W)
            flow = self.identity_flow + delta_flow

        flow = flow.permute(0, 2, 3, 1)
        delta_flow = delta_flow.permute(0, 2, 3, 1)
        return flow, delta_flow

    @torch.no_grad()
    def transfer_points(self, src_kps, src_idx, trg_idx, img, mask=None,
                        res=None, return_canon=False, is_flow=False):
        # src_kps are N x P x 2 (in xy format)

        # Compute flow from images
        if is_flow:
            flow = img
        else:
            flow, _ = self(img)

        # Step 1: Map the points in src to the canonical space
        max_batch_size = 2
        if src_kps.size(0) > max_batch_size:
            N = len(src_kps)
            points_canon = []
            for start_idx in range(0, N, max_batch_size):
                end_idx = min(start_idx+max_batch_size, N)

                points_canon_batch = self.transfer_forward(
                    flow[src_idx[start_idx:end_idx]],
                    src_kps[start_idx:end_idx], res=res, is_flow=True)
                points_canon.append(points_canon_batch)
            points_canon = torch.cat(points_canon, dim=0)
        else:
            points_canon = self.transfer_forward(flow[src_idx], src_kps,
                                                 res=res, is_flow=True)
        # points_canon = torch.clamp(points_canon, min=-1, max=1)

        # Step 2: Map the points in the canonical space to trg
        # This is a memory intensive step, so do a single image at a time
        # if the number of points are large
        if src_kps.size(1) > 256 or src_kps.size(0) > max_batch_size:
            N = len(src_kps)
            points_transfered = []
            for start_idx in range(0, N, max_batch_size):
                end_idx = min(start_idx+max_batch_size, N)
                points_transfered_single = self.transfer_reverse(
                    flow[[trg_idx[start_idx:end_idx]]],
                    points_canon[start_idx:end_idx], res=res,
                    mask=mask[trg_idx[start_idx:end_idx]], is_flow=True)
                points_transfered.append(points_transfered_single)
            points_transfered = torch.cat(points_transfered, dim=0)
        else:
            points_transfered = self.transfer_reverse(
                flow[trg_idx], points_canon, res=res, mask=mask[trg_idx],
                is_flow=True)

        if return_canon:
            points_canon = self.unnormalize(points_canon, res, res)
            return points_transfered, points_canon
        else:
            return points_transfered

    def transfer_forward(self, img, points, res=None, is_flow=False):

        # TODO: currently points generated by load_fg_points are not
        # scaled properly. Take a look
        # TODO: Also double check normalize and unnormalize logic
        # points are N x P x 2 (in xy format)
        # assume that the flow is also xy format
        points = self.normalize(points, res, res)
        if is_flow:
            flow = img
        else:
            flow, _ = self(img)
        flow_grid = flow.permute(0, 3, 1, 2)
        points_transfered = F.grid_sample(
            flow_grid, points.unsqueeze(2).float(),
            padding_mode='border', align_corners=True)
        points_transfered = points_transfered.squeeze(3).permute(0, 2, 1)

        return points_transfered

    def transfer_reverse(self, img, points, res=None, mask=None, is_flow=False):
        N = points.size(0)
        num_points = points.size(1)
        # points are N x P x 2 (in xy format)
        points = points
        if is_flow:
            flow = img
        else:
            flow, _ = self(img)
        if flow.size(1) != res:
            scale_factor = res/flow.size(1)
            flow = F.interpolate(
                flow.permute(0, 3, 1, 2),
                scale_factor=scale_factor,
                mode='bilinear').permute(0, 2, 3, 1)
        # From  (N, H, W, 2) to (N, H, W, 1, 1, 2)
        flow_reshaped = flow.unsqueeze(-2).unsqueeze(-2)

        # From (N, num_points, 2) to (N, 1, 1, num_points, 2, 1)
        points = points.unsqueeze(1).unsqueeze(1).unsqueeze(-1)

        # (N, H, W, num_points)
        similarities = (flow_reshaped @ points)[..., 0, 0]
        distances = points.pow(2).squeeze(-1).sum(dim=-1) + \
            flow_reshaped.pow(2).sum(dim=-1).squeeze(-1) - 2 * similarities

        if mask is not None:
            distances[mask.squeeze(1)<0.1] = float('inf')

        nearest_neighbors = distances.reshape(
            N, flow_reshaped.size(1) * flow_reshaped.size(2),
            num_points).argmin(dim=1)
        points_transfered = unravel_index(
            nearest_neighbors, (flow_reshaped.size(1), flow_reshaped.size(2)))
        return points_transfered

    @staticmethod
    def normalize(points, res, out_res):
        return points.div(out_res - 1).add(-0.5).mul(2).mul((res - 1) / res)

    @staticmethod
    def unnormalize(points, res, out_res):
        return points.div((res - 1) / res).div(2).add(0.5).mul(out_res - 1)


def sample_from_reverse_flow(flow, points):
    # Points are of size B x N x 2 in YX format
    B, N, _ = points.shape

    # Reshape flow from  (B, H, W, 2) to (B, H, W, 1, 1, 2)
    flow_reshaped = flow.unsqueeze(-2).unsqueeze(-2)

    # Reshape points from (B, N, 2) to (B, 1, 1, N, 2, 1)
    points = points.unsqueeze(1).unsqueeze(1).unsqueeze(-1)

    # (B, H, W, N)
    similarities = (flow_reshaped @ points)[..., 0, 0]
    distances = points.pow(2).squeeze(-1).sum(dim=-1) + \
        flow_reshaped.pow(2).sum(dim=-1).squeeze(-1) - 2 * similarities

    nearest_neighbors = distances.reshape(
        B, flow_reshaped.size(1) * flow_reshaped.size(2), N).argmin(dim=1)
    points_transfered = unravel_index(
        nearest_neighbors, (flow_reshaped.size(1), flow_reshaped.size(2)))
    return points_transfered


def unravel_index(indices, shape):
    # https://stackoverflow.com/a/65168284
    r"""Converts flat indices into unraveled coordinates in a target shape.

    This is a `torch` implementation of `numpy.unravel_index`.

    Args:
        indices: A tensor of (flat) indices, (*, N).
        shape: The targeted shape, (D,).

    Returns:
        The unraveled coordinates, (*, N, D).
    """

    coord = []

    for dim in reversed(shape):
        coord.append(indices % dim)
        indices = indices // dim

    coord = torch.stack(coord, dim=-1)

    return coord